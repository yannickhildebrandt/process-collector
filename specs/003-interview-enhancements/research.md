# Research: Interview Enhancements

## R1: bpmn-js Dynamic Re-rendering in Sidebar

**Decision**: Use the existing `BpmnViewer` component with a `key` prop tied to summary version to force re-mount, or call `importXML()` imperatively on XML change.

**Rationale**: bpmn-js `NavigatedViewer` supports `importXML()` for loading new diagrams. Re-calling it with updated XML replaces the diagram in-place. The existing component already uses `useEffect` with `[xml]` dependency — passing new XML triggers a re-render. For sidebar use, the container height should be constrained (e.g., 300px) with overflow scroll. `canvas.zoom("fit-viewport")` auto-scales.

**Alternatives considered**:
- Re-mounting the component via React `key` prop: Simpler but causes a flash (destroy + recreate viewer). Acceptable fallback if `importXML` causes issues.
- Using `bpmn-auto-layout` at runtime: The deterministic BPMN generator already produces layout coordinates, so auto-layout is unnecessary.

## R2: Vercel AI SDK v6 — generateObject with Anthropic Constraints

**Decision**: Use `z.array(z.object({...}))` instead of `z.record()` for all schemas sent to Anthropic via `generateObject`. Avoid `propertyNames`, `patternProperties`, and other unsupported JSON Schema features.

**Rationale**: Anthropic's structured output API rejects schemas containing `propertyNames` (generated by Zod's `z.record()`). This was already fixed in the ProcessSummary schema (conditions field changed from record to array). The same constraint applies to the new config extraction schema.

**Alternatives considered**:
- Using `mode: "tool"` instead of `mode: "json"` for generateObject: May work around schema restrictions but adds complexity. Not needed since array-of-objects is cleaner.

## R3: Auto-Greeting Generation at Interview Creation

**Decision**: Generate the greeting server-side in the POST /interviews endpoint using `generateText` with the interview's system prompt + a greeting instruction. Persist as the first InterviewMessage (orderIndex: 0, role: ASSISTANT). If AI fails, persist a static fallback greeting from i18n.

**Rationale**: Generating at creation time (clarified in spec) ensures the greeting is visible immediately when the employee opens the page, with zero loading delay. The greeting uses the same system prompt as the interview (which includes title, category, industry context), ensuring consistency.

**Alternatives considered**:
- Client-triggered greeting on page load: Adds visible delay and complexity (loading state, race conditions with user input). Rejected per clarification.
- Pre-written static greetings per category: No personalization. Rejected.

## R4: Consultant Config Chat — Extraction Approach

**Decision**: Use `generateObject` with a Zod schema matching `ProjectConfigurationData` (from `src/lib/validators/config-schema.ts`) to extract structured configuration from the conversation. The extraction runs after each AI response (like the interview summary extractor pattern). Display the extracted config in a preview panel.

**Rationale**: This mirrors the proven interview summary extraction pattern. The existing `ProjectConfigurationData` interface defines the target shape (industryClassification, processCategories, customTerminology, interviewTemplateRefs). Using the same Zod-based extraction ensures the output is immediately validatable.

**Alternatives considered**:
- Having the AI return config as part of its text response and parsing it: Fragile, unreliable. Rejected.
- Using function calling / tool use: Adds complexity with no benefit over generateObject. Rejected.

## R5: Summary Panel Bug — Root Cause Analysis

**Decision**: The summary panel updates are working at the data level (extractSummary runs in onFinish, saves to DB, interview page re-fetches after 2s). The issue was that `z.record(z.string(), z.string())` in the ProcessSummary schema produced `propertyNames` which Anthropic rejected with a 400 error. This was already fixed (changed to array of objects). Verify the fix works end-to-end.

**Rationale**: The server logs showed `output_format.schema: For 'object' type, property 'propertyNames' is not supported` — a clear schema validation error from Anthropic. The chat endpoint's `onFinish` callback catches this error silently, so the summary simply never updates.

**Alternatives considered**:
- Polling instead of re-fetch on callback: Unnecessary — the existing callback pattern is correct, the schema was the only blocker.
